{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ibwqA_g_P3-7",
        "outputId": "dfb44e86-b567-467c-9458-83708a2f1bc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Flory-Huggins χ parameter = (Mvol*Ra^2)/4RT  Polymer Concentration (wt%)  \\\n",
            "0                                       0.0049                         22.0   \n",
            "1                                       0.0049                         22.0   \n",
            "2                                       0.0049                         22.0   \n",
            "3                                       0.0049                         22.0   \n",
            "4                                       0.0049                         22.0   \n",
            "\n",
            "   δ* =Sum of Products of Volume Fraction and δ of Individual Solvents  \\\n",
            "0                                           22.77125                     \n",
            "1                                           22.77125                     \n",
            "2                                           22.77125                     \n",
            "3                                           22.77125                     \n",
            "4                                           22.77125                     \n",
            "\n",
            "     RED  Beads  Voltage (kV)  Distance (cm)  \n",
            "0  0.0751   YES          12.0           15.0  \n",
            "1  0.0751   YES          12.0           15.0  \n",
            "2  0.0751   YES          12.0           15.0  \n",
            "3  0.0751   YES          12.0           15.0  \n",
            "4  0.0751   YES          12.0           15.0  \n",
            "          Chi     Conc.     delta      RED    Voltage  Distance\n",
            "0    0.005587  0.627803  0.575593  0.000000  0.107692   0.48583\n",
            "1    0.005587  0.627803  0.575593  0.000000  0.107692   0.48583\n",
            "2    0.005587  0.627803  0.575593  0.000000  0.107692   0.48583\n",
            "3    0.005587  0.627803  0.575593  0.000000  0.107692   0.48583\n",
            "4    0.005587  0.627803  0.575593  0.000000  0.107692   0.48583\n",
            "..        ...       ...       ...       ...       ...       ...\n",
            "360  0.029174  0.538117  0.600000  0.067727  0.138462   0.48583\n",
            "361  0.029174  0.538117  0.600000  0.067727  0.138462   0.48583\n",
            "362  0.029174  0.538117  0.600000  0.067727  0.138462   0.48583\n",
            "363  0.029174  0.538117  0.600000  0.067727  0.138462   0.48583\n",
            "364  0.029174  0.538117  0.600000  0.067727  0.138462   0.48583\n",
            "\n",
            "[365 rows x 6 columns]\n",
            "Accuracy of Logistic Regression: 0.7\n",
            "Accuracy of SVM 0.8090909090909091\n",
            "Accuracy of Gaussian Bayes: 0.7545454545454545\n",
            "Accuracy of Categorical Gaussian Bayes: 0.5909090909090909\n",
            "Accuracy of XGboost: 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-fc6fbef357a9>:151: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  X_c = X_train[y_train == c]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-fc6fbef357a9>\u001b[0m in \u001b[0;36m<cell line: 239>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0mgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"different\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy of Gaussian Bayes with full covariance matrix:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-fc6fbef357a9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;31m#iterate over each unique class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mX_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0mGaussianBayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mGaussianBayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpriors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3796\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3798\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3849\u001b[0m         \u001b[0;31m# check_bool_indexer will throw exception if Series key cannot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;31m# be reindexed to match DataFrame rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3851\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3852\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3853\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2552\u001b[0;31m             raise IndexingError(\n\u001b[0m\u001b[1;32m   2553\u001b[0m                 \u001b[0;34m\"Unalignable boolean Series provided as \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2554\u001b[0m                 \u001b[0;34m\"indexer (index of the boolean Series and of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data_frame = pd.read_csv(\"/content/Bead_prediction_data_6_features.csv\")\n",
        "\n",
        "\n",
        "#Preprocessing of data\n",
        "feature_rename_dictionary = { 'Flory-Huggins χ parameter = (Mvol*Ra^2)/4RT':'Chi', 'Polymer Concentration (wt%)':\"Conc.\",\n",
        "              'δ* =Sum of Products of Volume Fraction and δ of Individual Solvents':'delta',\n",
        "              \"Voltage (kV)\":\"Voltage\", \"Distance (cm)\":\"Distance\"}\n",
        "            \n",
        "print(data_frame.head())\n",
        "\n",
        "data_frame = data_frame.rename(columns = feature_rename_dictionary)\n",
        "\n",
        "# different_bead_values_count = data_frame[\"Beads\"].value_counts(dropna = False)\n",
        "# print(different_bead_values_count)\n",
        "\n",
        "data_frame = data_frame.dropna()\n",
        "\n",
        "combine_yes_no = {\"Yes\" : \"YES\", \"No\" : \"NO\"}\n",
        "data_frame[\"Beads\"] = data_frame[\"Beads\"].replace(combine_yes_no)\n",
        "\n",
        "encode_yes_no = {\"YES\" : 1, \"NO\" : 0}\n",
        "data_frame[\"Beads\"] = data_frame[\"Beads\"].replace(encode_yes_no)\n",
        "\n",
        "# print(data_frame)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# print(data_frame.columns)\n",
        "\n",
        "columns_to_scale = ['Chi', 'Conc.', 'delta', 'RED ', 'Voltage', 'Distance']\n",
        "scaled_data = scaler.fit_transform(data_frame[columns_to_scale])\n",
        "data_frame_scaled = pd.DataFrame(scaled_data, columns=columns_to_scale)\n",
        "print(data_frame_scaled)\n",
        "\n",
        "\n",
        "X = data_frame_scaled\n",
        "y = data_frame['Beads']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression classifier \n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "log_reg = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0,  solver='liblinear',\n",
        "                                              max_iter=1000 )\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of Logistic Regression:\", accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Supper Vector Machine classifier with RBF kernel\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC( C=1.0, kernel='rbf', degree=3)\n",
        "\n",
        "\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of SVM\", accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Naive Gaussian Bayes classifier\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "y_pred = gnb.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of Gaussian Bayes:\", accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Categorical Naive Bayes classifier \n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "\n",
        "gnb_cat = CategoricalNB()\n",
        "gnb_cat.fit(X_train, y_train)\n",
        "\n",
        "y_pred = gnb_cat.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy of Categorical Gaussian Bayes:\", accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#XGboost classifier with 200 rounds\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test)\n",
        "\n",
        "params = {\n",
        "    'objective': 'binary:logistic',  # Binary classification problem\n",
        "    'eval_metric': 'logloss'  # Evaluation metric\n",
        "}\n",
        "\n",
        "num_rounds = 200  \n",
        "model = xgb.train(params, dtrain, num_rounds)\n",
        "\n",
        "\n",
        "y_pred = model.predict(dtest)\n",
        "y_pred_binary = [1 if val >= 0.5 else 0 for val in y_pred]\n",
        "\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "print(\"Accuracy of XGboost:\", accuracy)\n"
      ],
      "metadata": {
        "id": "P9RLT9qmm9_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gaussian Bayes classifier with actual covariance matrix\n",
        "\n",
        "import numpy as np\n",
        "encode_yes_no = {\"YES\" : 1, \"NO\" : 2}\n",
        "data_frame[\"Beads\"] = data_frame[\"Beads\"].replace(encode_yes_no)\n",
        "X = data_frame_scaled\n",
        "y = data_frame['Beads']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
        "\n",
        "class GaussianBayes:\n",
        "    # input the variant you want to use with the declaration of class\n",
        "    def __init__(self, variant=\"different\"):\n",
        "        self.variant = variant\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        GaussianBayes.mean = {}\n",
        "        std = 0\n",
        "        GaussianBayes.cov = {}\n",
        "        GaussianBayes.priors = {}\n",
        "        #iterate over each unique class\n",
        "        for c in np.unique(y_train):\n",
        "            X_c = X_train[y_train == c]\n",
        "            GaussianBayes.mean[c] = np.mean(X_c, axis=0)\n",
        "            GaussianBayes.priors[c] = np.size(X_c)/np.size(X_train)\n",
        "            std += np.std(X_c, axis=0)\n",
        "\n",
        "        GaussianBayes.std_mean = np.mean(np.array(std))\n",
        "\n",
        "        if(self.variant == \"same\"):\n",
        "            GaussianBayes.cov = np.cov(X_train.T)\n",
        "\n",
        "        elif(self.variant == \"different\"):\n",
        "            for c in np.unique(y_train):\n",
        "                X_c = X_train[y_train == c]\n",
        "                GaussianBayes.cov[c] = np.ma.cov(np.array(X_c).T)\n",
        "\n",
        "        GaussianBayes.uniques = np.unique(y_train)\n",
        "\n",
        "    def test(self, X_test, y_test):\n",
        "\n",
        "        pred_class=self.predict(X_test)\n",
        "\n",
        "        pred_class = np.array(pred_class)\n",
        "        true_class = np.array(y_test)\n",
        "\n",
        "        correct_pred = 0\n",
        "        for i in range(len(pred_class)):\n",
        "            if pred_class[i] == true_class[i]:\n",
        "                correct_pred += 1\n",
        "        return correct_pred/len(pred_class)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        pred_class = []\n",
        "        for sample in np.array(X_test):\n",
        "            values = []\n",
        "\n",
        "            if(self.variant == \"different\"):\n",
        "\n",
        "                for c in GaussianBayes.uniques:\n",
        "\n",
        "                    x = (sample-GaussianBayes.mean[c])\n",
        "                    cov_inv = np.linalg.inv(GaussianBayes.cov[c])\n",
        "\n",
        "                    x_new = -0.5 *(x) @ cov_inv @ (x).T\n",
        "\n",
        "                    det = np.linalg.det(GaussianBayes.cov[c])\n",
        "\n",
        "                    value = x_new - 0.5 * np.log(det) + np.log(GaussianBayes.priors[c])\n",
        "                    values.append(value)\n",
        "\n",
        "                pred=np.argmax(np.array(values))+1\n",
        "\n",
        "                pred_class.append(pred)\n",
        "\n",
        "            if(self.variant == \"same\"):\n",
        "\n",
        "                for c in GaussianBayes.uniques:\n",
        "\n",
        "                    x = (sample-GaussianBayes.mean[c])\n",
        "                    cov_inv = np.linalg.inv(GaussianBayes.cov)\n",
        "\n",
        "                    x_new = -0.5 *(x).T @ cov_inv @ (x).T\n",
        "                    value = x_new\n",
        "\n",
        "                    values.append(value)\n",
        "                pred=np.argmax(np.array(values))+1\n",
        "                # print(np.argmax(values))\n",
        "                pred_class.append(pred)\n",
        "\n",
        "            if(self.variant == \"independent\"):\n",
        "\n",
        "                for c in GaussianBayes.uniques:\n",
        "                    x = (sample-GaussianBayes.mean[c])\n",
        "                    # cov_inv=np.linalg.inv(GaussianBayes.cov)\n",
        "                    \n",
        "                    x_new = -0.5 *(x) @ (x).T\n",
        "                    value = x_new/GaussianBayes.std_mean\n",
        "                    values.append(value)\n",
        "                    # print(value)\n",
        "                # values=np.array(values + \"*\")\n",
        "                pred=np.argmax(np.array(values))+1\n",
        "                # print(np.argmax(values))\n",
        "                pred_class.append(pred)\n",
        "\n",
        "        return np.array(pred_class)\n",
        "\n",
        "\n",
        "gb = GaussianBayes(variant = \"different\")\n",
        "\n",
        "gb.train(X_train, y_train)\n",
        "accuracy = gb.test(X_test,y_test)\n",
        "print(\"Accuracy of Gaussian Bayes with full covariance matrix:\", accuracy)"
      ],
      "metadata": {
        "id": "ZFXj_2ANm4Mg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}